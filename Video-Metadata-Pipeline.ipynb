{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Stock Video Metadata Pipeline"
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Running on host - Cell 1: Install dependencies\n!pip install pandas opencv-python Pillow transformers torch paramiko ultralytics",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": "# Running on Mobile - Cell 1: Install dependencies\n!pip install pandas opencv-python Pillow ultralytics paramiko\n# (Skip transformers/torch on mobile if you don‚Äôt need captioning here)",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": " System commands are not supported in Juno (yet)\n",
     "name": "stderr"
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Cell 2: Imports & Paths (fault‚Äêtolerant for missing crypto libs)\nimport sys\nfrom pathlib import Path\nimport pandas as pd\n\n# 1) Locate & add the `scripts/` folder\nrepo_root = Path.cwd()\nscripts_path = repo_root / \"scripts\"\nif not scripts_path.is_dir():\n    raise FileNotFoundError(\"Missing 'scripts/' directory in repo root\")\nsys.path.insert(0, str(scripts_path))\n\n# 2) Import pipeline modules, with graceful fallbacks\nfrom config      import get_smb_root, get_repo_root\nfrom discovery   import discover_video_batches, save_inventory\n\n# enrichment is already fault‚Äêtolerant per our earlier patch\nfrom enrichment  import enrich_dataframe\n\nfrom export      import export_blackbox_csv, export_blackbox_xml\n\n# upload may warn if Paramiko isn‚Äôt installed\nfrom upload      import upload_batch_or_zip\n\n# 3) Resolve key paths\nbatches_root = get_smb_root()\nmetadata_dir  = repo_root / \"metadata\"\nmetadata_dir.mkdir(exist_ok=True)\n\nprint(\"üìÇ Repo root:    \", repo_root)\nprint(\"üìÇ Batches root: \", batches_root)\nprint(\"üìÇ Metadata dir: \", metadata_dir)",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": "‚ö†Ô∏è Could not load captioning model (Failed to import transformers.pipelines because of the following error (look up to see its traceback):\ncannot import name 'BertTokenizerFast' from 'transformers.models.bert' (/var/mobile/Containers/Data/Application/7EDC4B92-10B9-48D7-ADEA-ABBF5DF8C7B7/Documents/site-packages/transformers/models/bert/__init__.py)); skipping captions\n‚ö†Ô∏è  Paramiko not installed. SFTP upload disabled; will create ZIP archives instead.\nüìÇ Repo root:     /private/var/mobile/Containers/Shared/AppGroup/08003265-A677-4358-B939-7E86CE490040/File Provider Storage/Repositories/cda_ASSETS/blackbox-stock-video-metadata\nüìÇ Batches root:  B:/Video/StockFootage/Batches\nüìÇ Metadata dir:  /private/var/mobile/Containers/Shared/AppGroup/08003265-A677-4358-B939-7E86CE490040/File Provider Storage/Repositories/cda_ASSETS/blackbox-stock-video-metadata/metadata\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Cell 3: Load or Discover Inventory Metadata\nfrom pprint import pprint\n\nbatches = {}\n\ntry:\n    if 'batches_root' in globals() and batches_root and batches_root.exists():\n        print(f\"üìÇ Using discovered video batches from: {batches_root}\")\n        batches = discover_video_batches(batches_root)\n        if batches:\n            save_inventory(\n                batches,\n                out_json = metadata_dir / \"batch_metadata.json\",\n                out_csv  = metadata_dir / \"video_inventory.csv\"\n            )\n            print(f\"‚úÖ Discovered {len(batches)} batches and saved metadata.\")\n        else:\n            print(\"‚ö†Ô∏è No batches discovered.\")\n\n    elif (metadata_dir / \"video_inventory.csv\").exists():\n        print(f\"üìÅ Loading video inventory from existing CSV in: {metadata_dir}\")\n        df_inventory = pd.read_csv(metadata_dir / \"video_inventory.csv\")\n        print(f\"‚úÖ Loaded {len(df_inventory)} video entries from CSV.\")\n        batches = None  # discovery dict not used in this fallback path\n\n    else:\n        raise FileNotFoundError(\"Neither batches directory nor video inventory CSV is available.\")\n\n    # Show preview if we discovered or loaded something\n    if batches:\n        pprint({k: len(v) for k, v in batches.items()})\n    elif 'df_inventory' in locals():\n        print(df_inventory[[\"filename\", \"full_path\"]].head())\n\nexcept FileNotFoundError as e:\n    print(f\"‚ùå Error: {e}\")\n    print(\"üí° Make sure either `batches_root` is valid or `video_inventory.csv` exists.\")\n\nexcept Exception as e:\n    print(f\"üö® Unexpected error:\\n{e}\")",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": "üìÅ Loading video inventory from existing CSV in: /private/var/mobile/Containers/Shared/AppGroup/08003265-A677-4358-B939-7E86CE490040/File Provider Storage/Repositories/cda_ASSETS/blackbox-stock-video-metadata/metadata\n‚úÖ Loaded 16 video entries from CSV.\n       filename                                          full_path\n0  Z7V_1648.MP4  B:\\Video\\StockFootage\\Batches\\well_pump\\Z7V_16...\n1  Z7V_1649.MP4  B:\\Video\\StockFootage\\Batches\\well_pump\\Z7V_16...\n2  Z7V_1650.MP4  B:\\Video\\StockFootage\\Batches\\well_pump\\Z7V_16...\n3  Z7V_1651.MP4  B:\\Video\\StockFootage\\Batches\\well_pump\\Z7V_16...\n4  Z7V_1652.MP4  B:\\Video\\StockFootage\\Batches\\well_pump\\Z7V_16...\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Cell 4: Enrich Inventory with AI Metadata (fallback-aware)\nimport pandas as pd\nfrom pathlib import Path\n\ndf_videos = None\n\ntry:\n    inventory_csv = metadata_dir / \"video_inventory.csv\"\n    if not inventory_csv.exists():\n        raise FileNotFoundError(f\"Missing inventory file: {inventory_csv}\")\n\n    # Load video inventory\n    df_videos = pd.read_csv(inventory_csv)\n    print(f\"üì• Loaded {len(df_videos)} videos from inventory.\")\n\n    # Drop entries without a valid full_path\n    df_videos = df_videos[df_videos[\"full_path\"].notna()]\n    if df_videos.empty:\n        raise ValueError(\"No valid video paths to enrich.\")\n\n    # Try enrichment (captioning + keywords)\n    try:\n        df_videos = enrich_dataframe(df_videos)\n        print(f\"‚ú® Enriched {len(df_videos)} videos with AI metadata.\")\n    except ImportError as e:\n        print(f\"‚ö†Ô∏è Enrichment module failed due to missing dependencies: {e}\")\n        print(\"üí° Skipping enrichment. Proceeding with raw metadata only.\")\n    except Exception as e:\n        print(f\"üö® Error during enrichment:\\n{e}\")\n        print(\"üí° Skipping enrichment. Check enrichment module for debugging.\")\n\n    # Preview\n    preview_cols = [\"filename\", \"Description\", \"Keywords\"] if \"Description\" in df_videos.columns else [\"filename\"]\n    display(df_videos[preview_cols].head())\n\nexcept FileNotFoundError as e:\n    print(f\"‚ùå Inventory not found: {e}\")\n    print(\"üí° Ensure that `video_inventory.csv` was generated or copied to the metadata directory.\")\n\nexcept Exception as e:\n    print(f\"üö® Unexpected error while loading inventory:\\n{e}\")",
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": "üì• Loaded 16 videos from inventory.\n‚ú® Enriched 16 videos with AI metadata.\n",
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "       filename Description Keywords\n0  Z7V_1648.MP4                     \n1  Z7V_1649.MP4                     \n2  Z7V_1650.MP4                     \n3  Z7V_1651.MP4                     \n4  Z7V_1652.MP4                     ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Description</th>\n      <th>Keywords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Z7V_1648.MP4</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Z7V_1649.MP4</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Z7V_1650.MP4</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Z7V_1651.MP4</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Z7V_1652.MP4</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üì§ Optional ‚Äî Save the enriched version\n\nIf enrich_dataframe() runs successfully, you can persist results:"
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "(df_videos if df_videos is not None else df_inventory).to_csv(metadata_dir / \"enriched_videos.csv\", index=False)",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Modular Cell 5"
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Cell 5: Export BlackBox‚ÄêReady CSV + XML\nfrom scripts.export import export_blackbox_csv, export_blackbox_xml\n\n# 1) Export the three‚Äêcolumn CSV\ncsv_path = metadata_dir / \"blackbox_metadata.csv\"\nexport_blackbox_csv(df_videos, csv_path)\n\n# 2) Export one metadata.xml per batch, creating any missing batch folders\nexport_blackbox_xml(df_videos, batches_root)",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": "‚úÖ Exported CSV: /private/var/mobile/Containers/Shared/AppGroup/08003265-A677-4358-B939-7E86CE490040/File Provider Storage/Repositories/cda_ASSETS/blackbox-stock-video-metadata/metadata/blackbox_metadata.csv\n‚úÖ Exported XML for batch `well_pump`: B:/Video/StockFootage/Batches/well_pump/metadata.xml\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# (Ignore for Modular `script`) Cell 5: Export BlackBox‚ÄêReady CSV + XML (Safe, Cross-Platform)\n\ncsv_path = metadata_dir / \"blackbox_metadata.csv\"\nxml_errors = []\n\ntry:\n    export_blackbox_csv(df_videos, csv_path)\n    print(f\"‚úÖ Exported BlackBox CSV:\\nüìÑ {csv_path}\")\nexcept Exception as e:\n    print(f\"‚ùå Failed to export CSV: {e}\")\n\ntry:\n    # Ensure all XML batch subdirs exist before writing\n    if not batches_root.exists():\n        raise FileNotFoundError(f\"Batches root not found: {batches_root}\")\n    \n    # Patch export_blackbox_xml to create dirs if needed\n    from xml.etree import ElementTree as ET\n    from scripts.export import export_blackbox_xml as original_export_xml\n\n    def export_blackbox_xml_safe(df, batches_root):\n        from collections import defaultdict\n        from pathlib import Path\n        import xml.etree.ElementTree as ET\n\n        grouped = df.groupby(\"batch\")\n        for batch, group in grouped:\n            batch_dir = batches_root / batch\n            if not batch_dir.exists():\n                try:\n                    batch_dir.mkdir(parents=True, exist_ok=True)\n                    print(f\"üìÅ Created missing batch directory: {batch_dir}\")\n                except Exception as e:\n                    xml_errors.append((batch, str(e)))\n                    continue\n            \n            root = ET.Element(\"videos\")\n            for _, row in group.iterrows():\n                video_el = ET.SubElement(root, \"video\")\n                ET.SubElement(video_el, \"filename\").text = row.get(\"filename\", \"\")\n                ET.SubElement(video_el, \"description\").text = row.get(\"Description\", \"\")\n                ET.SubElement(video_el, \"keywords\").text = row.get(\"Keywords\", \"\")\n            \n            xml_path = batch_dir / \"metadata.xml\"\n            try:\n                tree = ET.ElementTree(root)\n                tree.write(str(xml_path), encoding=\"utf-8\", xml_declaration=True)\n                print(f\"‚úÖ Exported XML for {batch}: {xml_path}\")\n            except Exception as e:\n                xml_errors.append((batch, str(e)))\n\n    # Call patched exporter\n    export_blackbox_xml_safe(df_videos, batches_root)\n\n    if xml_errors:\n        print(f\"\\n‚ö†Ô∏è XML export completed with {len(xml_errors)} errors:\")\n        for batch, err in xml_errors:\n            print(f\" - Batch `{batch}`: {err}\")\n\nexcept Exception as e:\n    print(f\"üö® Failed during XML export: {e}\")\n    print(\"üí° Ensure `batches_root` is accessible and batch folders exist or can be created.\")",
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "text": "‚úÖ Exported CSV: /private/var/mobile/Containers/Shared/AppGroup/08003265-A677-4358-B939-7E86CE490040/File Provider Storage/Repositories/cda_ASSETS/blackbox-stock-video-metadata/metadata/blackbox_metadata.csv\n‚úÖ Exported BlackBox CSV:\nüìÑ /private/var/mobile/Containers/Shared/AppGroup/08003265-A677-4358-B939-7E86CE490040/File Provider Storage/Repositories/cda_ASSETS/blackbox-stock-video-metadata/metadata/blackbox_metadata.csv\nüö® Failed during XML export: 'batch'\nüí° Ensure `batches_root` is accessible and batch folders exist or can be created.\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Modular Cell 6"
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Upload or ZIP per batch\nfrom upload import upload_batch_or_zip\nzip_dir = metadata_dir/\"blackbox_uploads\"\nfor batch_name in df_videos['batch_name'].unique():\n    batch_path = batches_root/batch_name\n    upload_batch_or_zip(batch_path, zip_dir)",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "text": "üì¶ Created ZIP for manual upload: /private/var/mobile/Containers/Shared/AppGroup/08003265-A677-4358-B939-7E86CE490040/File Provider Storage/Repositories/cda_ASSETS/blackbox-stock-video-metadata/metadata/blackbox_uploads/well_pump.zip\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# (Ignore for modular scripts) Cell 6: Upload All Batches to BlackBox SFTP\nfor batch_name in df_videos['batch_name'].unique():\n    upload_batch(batches_root / batch_name)\n\nprint(\"üéâ Upload complete for all batches.\")",
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'upload_batch' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-28ef4b312fb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# (Ignore for modular scripts) Cell 6: Upload All Batches to BlackBox SFTP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_videos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mupload_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches_root\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üéâ Upload complete for all batches.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'upload_batch' is not defined"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}